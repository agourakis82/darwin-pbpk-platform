# üöÄ Treinamento Dynamic GNN - Em Andamento

**Data de In√≠cio:** 06 de Novembro de 2025  
**Status:** ‚è≥ **RODANDO EM BACKGROUND**

---

## üìä CONFIGURA√á√ÉO DO TREINAMENTO

### Dataset:
- **Arquivo:** `data/dynamic_gnn_training_full/training_data.npz`
- **Amostras:** 1000 (800 train, 200 val)
- **Tamanho:** 10.26 MB
- **Time points:** 100 por amostra
- **√ìrg√£os:** 14 compartimentos

### Modelo:
- **Par√¢metros:** 155,972
- **Arquitetura:** Dynamic GNN (14 √≥rg√£os, 3 GNN layers, GRU temporal)
- **Device:** CPU (GPU recomendado para mais velocidade)

### Hiperpar√¢metros:
- **√âpocas:** 50
- **Batch size:** 8
- **Learning rate:** 1e-3
- **Optimizer:** Adam
- **Scheduler:** ReduceLROnPlateau (patience=5, factor=0.5)

### Output:
- **Diret√≥rio:** `models/dynamic_gnn_full/`
- **Arquivos:**
  - `best_model.pt` - Melhor modelo (menor val loss)
  - `final_model.pt` - √öltima √©poca
  - `training_curve.png` - Curva de treinamento

---

## ‚è±Ô∏è ESTIMATIVA DE TEMPO

### CPU (atual):
- **Tempo por itera√ß√£o:** ~4-5 segundos
- **Itera√ß√µes por √©poca:** 100 (800 amostras / batch_size 8)
- **Tempo por √©poca:** ~7-8 minutos
- **Tempo total (50 √©pocas):** ~6-7 horas ‚è∞

### GPU (recomendado):
- **Tempo por itera√ß√£o:** ~0.1-0.2 segundos (20-50x mais r√°pido)
- **Tempo total (50 √©pocas):** ~15-30 minutos ‚ö°

---

## üìà MONITORAMENTO

### Ver Progresso:
```bash
# Seguir log em tempo real
tail -f training.log

# Ver √∫ltimas linhas
tail -30 training.log

# Ver apenas √©pocas e losses
tail -f training.log | grep -E "(Epoch|Loss|‚úÖ)"
```

### Verificar Processo:
```bash
# Ver se est√° rodando
ps aux | grep train_dynamic_gnn_pbpk

# Ver uso de CPU/RAM
top -p $(pgrep -f train_dynamic_gnn_pbpk)
```

### Parar Treinamento:
```bash
# Encontrar PID
pgrep -f train_dynamic_gnn_pbpk

# Parar (salva modelo atual)
kill <PID>
```

### Script de Monitoramento:
```bash
./scripts/monitor_training.sh
```

---

## üéØ RESULTADOS ESPERADOS

### Baseado no Paper (arXiv 2024):
- **R¬≤:** 0.9342 (target)
- **RMSE:** 0.0159
- **MAE:** 0.0116

### Progresso Esperado:
- **√âpocas 1-10:** Loss alto, aprendendo padr√µes b√°sicos
- **√âpocas 10-30:** Converg√™ncia, loss diminuindo
- **√âpocas 30-50:** Refinamento, otimiza√ß√£o final

---

## üìä M√âTRICAS A MONITORAR

### Durante Treinamento:
- **Train Loss:** Deve diminuir consistentemente
- **Val Loss:** Deve diminuir (sem overfitting)
- **Gap Train-Val:** Deve ser pequeno (< 20%)

### Ap√≥s Treinamento:
- **R¬≤ vs ODE Solver:** > 0.90 (target)
- **RMSE:** < 0.02
- **MAE:** < 0.015
- **Per-organ accuracy:** Especialmente blood, liver, kidney

---

## üîç VALIDA√á√ÉO P√ìS-TREINAMENTO

Ap√≥s o treinamento completar, validar:

1. **Compara√ß√£o com ODE Solver:**
   ```python
   # Carregar modelo treinado
   # Comparar predi√ß√µes vs ODE solver
   # Calcular R¬≤, RMSE, MAE
   ```

2. **Visualiza√ß√£o:**
   - Curvas de concentra√ß√£o vs tempo
   - Compara√ß√£o por √≥rg√£o
   - Residual plots

3. **M√©tricas por √ìrg√£o:**
   - Blood (cr√≠tico)
   - Liver (metabolismo)
   - Kidney (excre√ß√£o)
   - Brain (BBB)

---

## ‚ö†Ô∏è NOTAS IMPORTANTES

1. **Performance:** Treinamento em CPU √© muito lento. Se dispon√≠vel, usar GPU acelera 20-50x.

2. **Interrup√ß√£o:** Se precisar parar, o modelo atual ser√° salvo. Pode continuar depois.

3. **Converg√™ncia:** Se val loss parar de melhorar por 10+ √©pocas, considerar early stopping.

4. **Recursos:** Monitorar uso de RAM (dataset carregado na mem√≥ria).

---

## üìÅ ARQUIVOS GERADOS

Durante o treinamento:
- `training.log` - Log completo
- `models/dynamic_gnn_full/best_model.pt` - Melhor modelo (atualizado a cada melhoria)
- `models/dynamic_gnn_full/final_model.pt` - Modelo final (ao completar)
- `models/dynamic_gnn_full/training_curve.png` - Gr√°fico de losses

---

## üéâ PR√ìXIMOS PASSOS AP√ìS TREINAMENTO

1. ‚úÖ Validar modelo vs ODE solver
2. ‚úÖ Calcular m√©tricas (R¬≤, RMSE, MAE)
3. ‚úÖ Visualizar curvas de concentra√ß√£o
4. ‚úÖ Comparar com paper SOTA
5. ‚úÖ Documentar resultados
6. ‚úÖ Integrar no pipeline PBPK

---

**"Rigorous science. Honest results. Real impact."**

**Status:** ‚è≥ Treinamento em andamento (PID: verificar com `ps aux | grep train`)

