# üî¨ PLANO CIENT√çFICO SOTA - Darwin PBPK Platform

**Data:** 2025-11-08
**Objetivo:** Alcan√ßar performance SOTA (R¬≤ > 0.70) para publica√ß√£o Q1
**Foco:** CI√äNCIA RIGOROSA, n√£o funcionalidades

---

## üìä SITUA√á√ÉO ATUAL (HONESTA)

### Performance Atual vs Target SOTA

| Par√¢metro | R¬≤ Atual | Target SOTA | Gap | % Target |
|-----------|----------|-------------|-----|----------|
| **Clearance** | 0.18 | 0.70 | -0.52 | **26%** ‚ùå |
| **Vd** | 0.24 | 0.60 | -0.36 | **40%** ‚ùå |
| **Fu** | 0.19 | 0.50 | -0.31 | **38%** ‚ùå |

### Problemas Identificados

1. **Encoder Multimodal DESABILITADO**
   - D-MPNN (256d): ‚ùå Desabilitado ‚Üí Perdendo +0.15-0.20 R¬≤
   - SchNet (128d): ‚ùå Desabilitado ‚Üí Perdendo +0.10-0.15 R¬≤
   - **Total perdido: +0.25-0.35 R¬≤**

2. **Multi-task falhando**
   - 80%+ missing data impede multi-task eficaz
   - **Solu√ß√£o SOTA:** Single-task models primeiro

3. **Dynamic GNN n√£o validado**
   - Implementado mas n√£o comparado rigorosamente com ODE
   - Precisa valida√ß√£o cient√≠fica adequada

---

## üéØ OBJETIVOS CIENT√çFICOS

### Objetivo 1: Reativar Encoder Multimodal Completo
**Target:** R¬≤ 0.48-0.59 (70-98% do target SOTA)

**A√ß√µes:**
1. Criar script de treinamento usando `MultimodalMolecularEncoder` completo
2. Habilitar D-MPNN + SchNet
3. Treinar modelos single-task (Clearance, Vd, Fu separadamente)
4. Validar com m√©tricas rigorosas

**M√©tricas de Sucesso:**
- Clearance: R¬≤ > 0.48 (vs 0.18 atual)
- Vd: R¬≤ > 0.54 (vs 0.24 atual)
- Fu: R¬≤ > 0.49 (vs 0.19 atual)

### Objetivo 2: Implementar Single-Task Models
**Target:** R¬≤ > 0.50 para Clearance (32k samples dispon√≠veis)

**Justificativa Cient√≠fica:**
- Multi-task n√£o funciona com missing data extensivo
- Literatura mostra que single-task supera multi-task neste cen√°rio
- Clearance tem dataset maior (32k vs 6-7k para Fu/Vd)

**A√ß√µes:**
1. Criar `apps/training/03_single_task_clearance.py`
2. Usar encoder multimodal completo (976d)
3. Arquitetura: MLP [1024, 512, 256, 128]
4. Loss: MSE com log1p transform
5. Valida√ß√£o: 5-fold cross-validation

### Objetivo 3: Validar Dynamic GNN Cientificamente
**Target:** R¬≤ > 0.90 (vs 0.85-0.90 ODE tradicional)

**A√ß√µes:**
1. Gerar dataset de valida√ß√£o (1000+ simula√ß√µes)
2. Comparar Dynamic GNN vs ODE solver
3. M√©tricas: R¬≤, RMSE, MAE, 2-fold accuracy
4. An√°lise estat√≠stica rigorosa (t-test, effect size)

### Objetivo 4: Compara√ß√£o com Benchmarks da Literatura
**Target:** Superar ou igualar benchmarks publicados

**Benchmarks a Comparar:**
- TDC ADME Benchmark (R¬≤ 0.44 ensemble)
- ChEMBL PK predictions (R¬≤ 0.35-0.55)
- Yang et al. 2019 (R¬≤ 0.70-0.75)

**M√©tricas:**
- R¬≤ por par√¢metro
- 2-fold accuracy
- RMSE normalizado
- Teste estat√≠stico vs baseline

---

## üìã PLANO DE EXECU√á√ÉO (CIENT√çFICO)

### Fase 1: Quick Win Cient√≠fico (1 semana)

**Semana 1, Dia 1-2: Reativar Encoder Multimodal**
- [ ] Criar script `apps/training/04_multimodal_full.py`
- [ ] Usar `MultimodalMolecularEncoder` com D-MPNN + SchNet habilitados
- [ ] Treinar modelos single-task (Clearance-first)
- [ ] Documentar resultados vs baseline

**Semana 1, Dia 3-4: Single-Task Clearance**
- [ ] Implementar modelo Clearance-only
- [ ] Treinar em dataset completo (32k samples)
- [ ] Valida√ß√£o 5-fold cross-validation
- [ ] Comparar com literatura

**Semana 1, Dia 5: An√°lise e Documenta√ß√£o**
- [ ] An√°lise estat√≠stica completa
- [ ] Compara√ß√£o com benchmarks
- [ ] Documentar metodologia rigorosamente

**Target Fase 1:** Clearance R¬≤ > 0.50

### Fase 2: Valida√ß√£o Rigorosa (2 semanas)

**Semana 2: Valida√ß√£o Dynamic GNN**
- [ ] Gerar dataset de valida√ß√£o (1000+ simula√ß√µes)
- [ ] Comparar Dynamic GNN vs ODE solver
- [ ] An√°lise estat√≠stica (t-test, effect size)
- [ ] Documentar vantagens/limita√ß√µes

**Semana 3: Valida√ß√£o Externa**
- [ ] Testar em datasets externos (DrugBank, PK-DB)
- [ ] Comparar com Simcyp/GastroPlus (se poss√≠vel)
- [ ] An√°lise de erro por classe de droga
- [ ] Identificar casos de falha

**Target Fase 2:** Dynamic GNN R¬≤ > 0.90 validado

### Fase 3: Refinamento e Publica√ß√£o (3-4 semanas)

**Semana 4-5: Ensemble e Otimiza√ß√£o**
- [ ] Implementar ensemble strategy (5x MLP + 3x GNN)
- [ ] Hyperparameter optimization (Optuna)
- [ ] Data augmentation (SMILES enumeration)
- [ ] Valida√ß√£o final

**Semana 6-7: Prepara√ß√£o para Publica√ß√£o**
- [ ] Reda√ß√£o de metodologia rigorosa
- [ ] Tabelas de resultados completas
- [ ] Figuras de qualidade publica√ß√£o
- [ ] Compara√ß√£o detalhada com literatura

**Target Fase 3:** R¬≤ > 0.70 em todos os par√¢metros

---

## üî¨ METODOLOGIA CIENT√çFICA

### 1. Valida√ß√£o Rigorosa

**Train/Val/Test Split:**
- Train: 80% (scaffold-based split)
- Val: 10% (early stopping)
- Test: 10% (avalia√ß√£o final)

**M√©tricas:**
- R¬≤ (coeficiente de determina√ß√£o)
- RMSE (root mean square error)
- MAE (mean absolute error)
- 2-fold accuracy (% dentro de 2x do valor real)
- Pearson correlation

**An√°lise Estat√≠stica:**
- Teste t para comparar modelos
- Effect size (Cohen's d)
- Intervalos de confian√ßa (95%)
- An√°lise de res√≠duos

### 2. Compara√ß√£o com Literatura

**Benchmarks:**
- TDC ADME Benchmark
- ChEMBL PK predictions
- Yang et al. 2019
- Outros trabalhos relevantes

**M√©tricas de Compara√ß√£o:**
- R¬≤ por par√¢metro
- Dataset size (ajustar por tamanho)
- M√©todo utilizado
- Limita√ß√µes identificadas

### 3. Reproduzibilidade

**Requisitos:**
- Seeds fixos (42)
- Vers√µes de pacotes documentadas
- Scripts completos e comentados
- Datasets com DOI

---

## üìä RESULTADOS ESPERADOS

### Performance Projetada

| Fase | Clearance R¬≤ | Vd R¬≤ | Fu R¬≤ | Status |
|------|--------------|-------|-------|--------|
| **Atual** | 0.18 | 0.24 | 0.19 | ‚ùå |
| **Fase 1** | 0.48-0.53 | 0.54-0.59 | 0.49-0.54 | ‚è≥ |
| **Fase 2** | 0.55-0.65 | 0.60-0.70 | 0.55-0.65 | ‚è≥ |
| **Fase 3** | **0.70+** | **0.65+** | **0.60+** | ‚è≥ |

### Publica√ß√£o Q1

**Target Journals:**
- Nature Machine Intelligence
- Journal of Chemical Information and Modeling (JCIM)
- Bioinformatics

**Requisitos:**
- R¬≤ > 0.70 para pelo menos 2 par√¢metros
- Valida√ß√£o externa robusta
- Compara√ß√£o com comerciais (se poss√≠vel)
- C√≥digo open-source com DOI

---

## üöÄ PR√ìXIMOS PASSOS IMEDIATOS

### Agora (Hoje):

1. **Criar script de treinamento multimodal completo**
   - Arquivo: `apps/training/04_multimodal_full.py`
   - Usar `MultimodalMolecularEncoder` com D-MPNN + SchNet
   - Single-task Clearance primeiro

2. **Treinar modelo Clearance-only**
   - Dataset: 32k samples
   - Encoder: Multimodal completo (976d)
   - Target: R¬≤ > 0.50

3. **Documentar resultados**
   - M√©tricas completas
   - Compara√ß√£o com baseline
   - An√°lise de erros

---

## üìù NOTAS IMPORTANTES

### Rigor Cient√≠fico

- **N√ÉO** aceitar resultados sem valida√ß√£o adequada
- **N√ÉO** comparar com benchmarks sem ajustar por tamanho de dataset
- **SEMPRE** documentar limita√ß√µes e falhas
- **SEMPRE** usar m√©tricas padr√£o da literatura

### Transpar√™ncia

- Documentar TODAS as decis√µes metodol√≥gicas
- Reportar TODOS os resultados (n√£o apenas os melhores)
- Identificar casos de falha
- Comparar honestamente com literatura

---

**"Rigorous science. Honest results. Real impact."**

**Pr√≥ximo passo:** Criar script de treinamento multimodal completo AGORA.

