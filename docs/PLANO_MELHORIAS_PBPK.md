# ğŸ¯ PLANO DE MELHORIAS PARA PBPK

**Data:** 28 de outubro de 2025  
**Objetivo:** Aumentar RÂ² de 0.054 para >0.30 e validar clinicamente

---

## ğŸ“Š SITUAÃ‡ÃƒO ATUAL

### Trial 84 (Melhor modelo atual)
```
âœ… Val RÂ²:  0.2333
âŒ Test RÂ²: 0.0540
   - Fu:        0.126
   - Vd:        0.098  
   - Clearance: -0.063 (NEGATIVO!)
```

### ComparaÃ§Ã£o com Benchmark Externo
```
âœ… Ensemble (XGB+RF+NN): RÂ² = 0.438
   - 2-fold accuracy: ~70%
   - Clinicamente aceitÃ¡vel
```

---

## ğŸ” PROBLEMAS IDENTIFICADOS

1. **âŒ Clearance com RÂ² negativo**
   - Modelo nÃ£o aprende nada para clearance
   - PrediÃ§Ãµes piores que baseline (mean)

2. **âŒ Overfitting severo**
   - Val RÂ² = 0.233 vs Test RÂ² = 0.054
   - Gap de -76%!

3. **âŒ Dataset pequeno**
   - 478 molÃ©culas (99.4% missing data)
   - NÃ£o generalize para test

4. **âŒ Transforms complexos**
   - Logit/log1p funcionam, mas nÃ£o resolvem tudo

---

## ğŸ’¡ 3 ESTRATÃ‰GIAS PARA MELHORAR

### EstratÃ©gia 1: DATA AUGMENTATION ğŸ“Š
**Problema:** 478 molÃ©culas Ã© muito pouco  
**SoluÃ§Ã£o:** Usar dados externos para prÃ©-treino

**ImplementaÃ§Ã£o:**
1. **ChEMBL ADME (29k molÃ©culas)**
   - Pre-train multi-task em ChEMBL
   - Fine-tune em KEC
   - âœ… JÃ TENTADO - Falhou (-28%)

2. **PubChem (~10k molÃ©culas biomateriais)**
   - Unsupervised pre-training
   - Denoising autoencoder
   - âœ… JÃ TENTADO - Falhou (-200%)

3. **ğŸ’¡ NOVA ABORDAGEM: Semi-Supervised Learning**
   - Usar ~100k molÃ©culas PubChem
   - Pseudo-labeling com modelo atual
   - Treinar em dados reais + pseudo-labels
   - Confidence-weighted loss

**Status:** âš ï¸  Tentativas falharam, precisa abordagem diferente

---

### EstratÃ©gia 2: PHYSICS-INFORMED FINE-TUNING ğŸ§ª
**Problema:** Modelo ignora fÃ­sica PBPK  
**SoluÃ§Ã£o:** Reativar physics loss com peso ajustado

**ImplementaÃ§Ã£o:**
1. **Physics Loss Components:**
   ```python
   L_total = L_data + Î» * L_physics
   
   L_physics = w1*L_mass_balance  # ConservaÃ§Ã£o de massa
             + w2*L_hepatic_flow   # Limite de clearance hepÃ¡tico
             + w3*L_clvd_ratio     # CL/Vd ratio constraints
   ```

2. **Adaptive Physics Weight:**
   - Î» = 0 no inÃ­cio
   - Aumentar gradualmente durante treino
   - Evita dominaÃ§Ã£o de physics loss

3. **Target-specific physics:**
   - Fu: Bound check (0 < fu < 1)
   - Vd: Volume plausÃ­vel (0.1 < Vd < 10 L/kg)
   - CL: Hepatic flow limit (< 1.5 L/min)

**Status:** â³ NÃƒO IMPLEMENTADO AINDA

---

### EstratÃ©gia 3: ENSEMBLE COM DIVERSIDADE ğŸ²
**Problema:** Single model nÃ£o capta toda variabilidade  
**SoluÃ§Ã£o:** Ensemble com DIFERENTES arquiteturas

**ImplementaÃ§Ã£o:**
1. **Diverse Ensemble Members:**
   - Model 1: GNN (graph structure)
   - Model 2: Transformer (sequence)
   - Model 3: Residual MLP (features)
   - Model 4: XGBoost (baseline)

2. **Weighted Average:**
   ```python
   y_pred = Î£ wi * yi
   onde wi baseado em validation performance
   ```

3. **Stacking (NÃ­vel 2):**
   - Meta-learner aprende a combinar
   - Usa outputs do Level 1 como features

**Status:** âœ… JÃ TENTADO - 10x Trial 84 com seeds diferentes
   - Resultado: Pior que single model (-36%)
   - **Precisa DIVERSIDADE, nÃ£o apenas seeds!**

---

## ğŸ¯ ESTRATÃ‰GIA RECOMENDADA (3 PASSOS)

### Passo 1: PHYSICS-INFORMED FINE-TUNING (1-2 dias)
```bash
# Script a criar
python scripts/finetune_physics_informed.py \
  --model results/trial84_evaluation/trial84_best.pt \
  --physics-weight 0.01 \
  --adaptive-lambda \
  --epochs 50
```

**Expectativa:** RÂ² 0.05 â†’ 0.15 (+200%)

---

### Passo 2: HETEROGENEOUS ENSEMBLE (2-3 dias)
```bash
# Treinar 4 modelos DIFERENTES
python scripts/train_gnn_pbpk.py      # GNN
python scripts/train_transformer_pbpk.py  # Transformer
python scripts/train_residual_pbpk.py     # ResNet-like
python scripts/train_xgboost_pbpk.py      # XGBoost

# Combinar
python scripts/ensemble_heterogeneous.py \
  --models gnn,transformer,residual,xgboost \
  --weighting validation
```

**Expectativa:** RÂ² 0.15 â†’ 0.25 (+67%)

---

### Passo 3: SEMI-SUPERVISED COM PUBCHEM (3-5 dias)
```bash
# Gerar pseudo-labels para 100k PubChem
python scripts/generate_pseudo_labels.py \
  --model results/ensemble_best.pt \
  --pubchem-smiles data/pubchem_100k.txt \
  --confidence-threshold 0.7

# Treinar com dados reais + pseudo-labels
python scripts/train_semisupervised.py \
  --real-data data/processed/kec_dataset_split.pkl \
  --pseudo-data data/pubchem_pseudo_labels.pkl \
  --pseudo-weight 0.3
```

**Expectativa:** RÂ² 0.25 â†’ 0.35 (+40%)

---

## ğŸ“ˆ ROADMAP COMPLETO

| Fase | AÃ§Ã£o | Tempo | RÂ² Esperado |
|------|------|-------|-------------|
| âœ… Atual | Trial 84 | - | 0.054 |
| ğŸŸ¡ Fase 1 | Physics-informed fine-tuning | 2 dias | 0.15 |
| ğŸŸ¡ Fase 2 | Heterogeneous ensemble | 3 dias | 0.25 |
| ğŸŸ¡ Fase 3 | Semi-supervised learning | 5 dias | 0.35 |
| ğŸŸ¢ **Meta** | **Sistema completo** | **10 dias** | **>0.30** |

---

## âœ… VALIDAÃ‡ÃƒO CLÃNICA

### MÃ©tricas de Sucesso
1. **RÂ² > 0.30** (estatÃ­stico)
2. **2-fold accuracy > 50%** (clÃ­nico)
3. **3-fold accuracy > 80%** (excelente)

### Datasets de ValidaÃ§Ã£o
- âœ… KEC Test (242 drugs)
- â³ DrugBank (100 drugs clÃ­nicos)
- â³ PK-DB (50 concentration-time curves)
- â³ FDA Real Data (30 drugs aprovados)

### Benchmark ComparaÃ§Ã£o
- Literature PBPK: 2-fold ~ 70-80%
- ML ensembles: RÂ² ~ 0.40-0.50
- **Target:** RÂ² > 0.30 + 2-fold > 60%

---

## ğŸš€ PRÃ“XIMOS PASSOS IMEDIATOS

1. **Implementar physics-informed fine-tuning**
   ```bash
   cd scripts
   nano finetune_physics_informed.py
   ```

2. **Treinar GNN para ensemble**
   ```bash
   nano train_gnn_pbpk.py
   ```

3. **Setup validaÃ§Ã£o externa**
   ```bash
   nano validate_external_datasets.py
   ```

---

## ğŸ“Š MÃ‰TRICAS DE PROGRESSO

**Acompanhar:**
- RÂ² test (alvo: >0.30)
- 2-fold accuracy (alvo: >60%)
- Bias per parameter
- Calibration (ECE)
- Inference time (<100ms)

**GrÃ¡ficos:**
- Predicted vs True
- Bland-Altman plots
- Error distribution
- Per-drug-class performance

---

## ğŸ’¡ CONCLUSÃƒO

**PROBLEMA REAL:** Overfitting + dataset pequeno + clearance ruim

**SOLUÃ‡ÃƒO:** 
1. Physics constraints (regulaÃ§Ã£o)
2. Ensemble heterogÃªneo (reduÃ§Ã£o de variÃ¢ncia)
3. Semi-supervised (mais dados)

**TIMELINE:** 10 dias para RÂ² > 0.30

**PRIORIDADE:** ComeÃ§ar por Physics-informed (quick win!)

---

**Ãšltima atualizaÃ§Ã£o:** 28/10/2025 08:30 UTC

