# üéØ PBPK SOTA - Plano de A√ß√£o Imediato

**Data:** 06 de Novembro de 2025  
**Baseado em:** Pesquisa profunda SOTA + Estado atual do c√≥digo

---

## ‚úÖ DESCOBERTAS IMPORTANTES

### 1. Encoder Multi-Modal J√Å EST√Å SOTA! ‚úÖ

**Implementado (Sprint 3):**
- ‚úÖ ChemBERTa 768d
- ‚úÖ D-MPNN 256d (Directed Message Passing)
- ‚úÖ SchNet 128d (3D convolutions)
- ‚úÖ Cross-Attention Fusion (8-head, 512d unified)
- ‚úÖ KEC 15d (NOVEL - c√≥digo do mestrado)
- ‚úÖ 3D Conformer 50d
- ‚úÖ QM 15d

**Total:** 976 dimensions (5 modalidades)

**Status:** ‚úÖ **COMPLETO E SOTA!**

**Problema:** D-MPNN e SchNet foram desabilitados no treinamento (para velocidade)

**A√ß√£o:** Reativar para obter R¬≤ completo (+0.30 esperado)

---

## üöÄ A√á√ïES IMEDIATAS (Prioridade)

### A√ß√£o 1: Reativar D-MPNN + SchNet no Treinamento ‚≠ê

**Arquivo:** `apps/training/02_gnn_model.py` ou similar

**Mudan√ßa:**
```python
# ATUAL (desabilitado):
use_dmpnn=False,
use_schnet=False,

# MUDAR PARA:
use_dmpnn=True,   # Reativar D-MPNN
use_schnet=True,  # Reativar SchNet
```

**Impacto Esperado:**
- +0.15-0.20 R¬≤ (D-MPNN - 2D topology)
- +0.10-0.15 R¬≤ (SchNet - 3D geometry)
- **Total: +0.25-0.35 R¬≤**

**Tempo:** 5 minutos (mudan√ßa de flag)

---

### A√ß√£o 2: Implementar Single-Task Models ‚≠ê‚≠ê

**Problema:** Multi-task falhando com 80%+ missing data

**Solu√ß√£o:** Single-task models (Clearance-first)

**Arquivo:** Criar `apps/training/03_single_task_clearance.py`

**Implementa√ß√£o:**
```python
# Model: Clearance-only
# Input: Multi-modal encoder (976d) OU ChemBERTa (768d)
# Architecture: MLP [1024, 512, 256, 128]
# Output: Single task (Clearance)
# Loss: MSE with log1p transform
# Epochs: 200
# Learning rate: 1e-4
```

**Target:** R¬≤ > 0.50 (32k samples dispon√≠veis!)

**Tempo:** 2-3 horas (implementa√ß√£o + treino)

---

### A√ß√£o 3: Implementar Dynamic GNN para PBPK ‚≠ê‚≠ê‚≠ê

**Breakthrough SOTA 2024:**
- R¬≤ 0.93+ vs 0.85-0.90 (ODE tradicional)
- Data-driven, menos par√¢metros

**Arquivo:** Criar `apps/pbpk_core/simulation/dynamic_gnn_pbpk.py`

**Arquitetura:**
```python
class DynamicPBPKGNN(nn.Module):
    """
    Dynamic Graph Neural Network para PBPK
    
    Graph: 14 √≥rg√£os (nodes)
    Edges: Fluxos sangu√≠neos, clearance
    Temporal: Evolution via GNN layers
    Attention: Critical organs (liver, kidney, brain)
    """
    def __init__(self):
        # 14-compartment graph
        # Dynamic edges (time-dependent)
        # GNN layers for temporal evolution
        # Attention mechanism
        pass
```

**Tempo:** 3-4 semanas (implementa√ß√£o completa)

**Impacto:** R¬≤ 0.93+ (vs 0.85-0.90 atual)

---

## üìã ROADMAP PRIORITIZADO

### Semana 1 (Imediato):
1. ‚úÖ Reativar D-MPNN + SchNet (5 min)
2. ‚è≥ Treinar modelo com encoder completo (2-3h)
3. ‚è≥ Implementar single-task Clearance (2-3h)
4. ‚è≥ Validar resultados

**Target:** Clearance R¬≤ > 0.50

### Semana 2-3:
5. ‚è≥ Ensemble strategy (5x MLP + 3x GNN)
6. ‚è≥ Hyperparameter optimization (Optuna)
7. ‚è≥ Fu-only e Vd-only models

**Target:** Clearance R¬≤ > 0.60

### Semana 4-6:
8. ‚è≥ Implementar Dynamic GNN
9. ‚è≥ Validar vs ODE solver
10. ‚è≥ Integrar no pipeline

**Target:** R¬≤ > 0.90 (Dynamic GNN)

---

## üí° RECOMENDA√á√ÉO ESTRAT√âGICA

### Op√ß√£o A: Quick Win (1 semana)
1. Reativar D-MPNN + SchNet
2. Single-task Clearance
3. **Resultado:** R¬≤ > 0.50-0.60

### Op√ß√£o B: Breakthrough (4-6 semanas)
1. Tudo da Op√ß√£o A
2. + Dynamic GNN
3. **Resultado:** R¬≤ > 0.90 (SOTA absoluto)

**Recomenda√ß√£o:** Come√ßar com Op√ß√£o A (quick win), depois Op√ß√£o B (breakthrough)

---

## üéØ PR√ìXIMO PASSO IMEDIATO

**Agora mesmo:**
1. Reativar D-MPNN + SchNet no c√≥digo de treinamento
2. Rodar treinamento com encoder completo
3. Comparar resultados vs encoder parcial

**Tempo total:** ~30 minutos (mudan√ßa + treino r√°pido)

---

**"Rigorous science. Honest results. Real impact."**

