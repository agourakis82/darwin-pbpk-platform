# üî¨ Treinamento Cient√≠fico SOTA - Cluster Distribu√≠do

**Criado:** 2025-11-08
**Autor:** Dr. Demetrios Chiuratto Agourakis
**Status:** ‚úÖ Pronto para execu√ß√£o no cluster

---

## üìã Resumo

Configura√ß√£o completa para execu√ß√£o do treinamento cient√≠fico **Single-Task Clearance** no cluster Kubernetes distribu√≠do (node Maria - L4 24GB).

---

## üéØ Objetivo Cient√≠fico

- **Target:** R¬≤ > 0.50 para Clearance
- **Metodologia:** Single-task model com encoder multimodal completo (976d)
- **Rigor:** Valida√ß√£o 5-fold cross-validation
- **Compara√ß√£o:** Benchmarks da literatura (TDC, ChEMBL)

---

## üìÅ Arquivos Criados

### 1. Job Kubernetes
**Arquivo:** `.darwin/cluster/k8s/training-job-clearance-sota.yaml`

- **Imagem:** `pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime`
- **Node:** Maria (L4 24GB)
- **Recursos:**
  - GPU: 1x NVIDIA L4
  - CPU: 6-8 cores
  - Mem√≥ria: 16-24 GiB
- **Volume:** Workspace compartilhado (`/workspace`)
- **TTL:** 48 horas ap√≥s conclus√£o

### 2. Script de Submiss√£o
**Arquivo:** `scripts/submit_clearance_sota.sh`

- Verifica kubectl e contexto do cluster
- Verifica node Maria
- Verifica/cria namespace `darwin-pbpk-platform`
- Submete job com valida√ß√µes

### 3. Script de Monitoramento
**Arquivo:** `scripts/monitor_clearance_sota.sh`

- Status do job e pods
- Uso de recursos (CPU, mem√≥ria)
- Logs recentes (√∫ltimas 30 linhas)
- Comandos √∫teis para debugging

### 4. Script de Treinamento Atualizado
**Arquivo:** `apps/training/03_single_task_clearance_multimodal.py`

- ‚úÖ Suporte a argumentos de linha de comando (`argparse`)
- ‚úÖ Configur√°vel via par√¢metros do job K8s
- ‚úÖ Fallback autom√°tico para TDC se dataset consolidado n√£o existir

---

## üöÄ Como Usar

### 1. Submeter Job

```bash
cd /home/agourakis82/workspace/darwin-pbpk-platform
./scripts/submit_clearance_sota.sh
```

### 2. Monitorar Progresso

```bash
# Monitoramento r√°pido
./scripts/monitor_clearance_sota.sh

# Logs em tempo real
kubectl logs -f -l component=training,version=sota-clearance -n darwin-pbpk-platform

# Status do job
kubectl get jobs clearance-sota-training -n darwin-pbpk-platform

# Status dos pods
kubectl get pods -l component=training,version=sota-clearance -n darwin-pbpk-platform
```

### 3. Verificar Resultados

Ap√≥s conclus√£o, os resultados estar√£o em:

```
/workspace/darwin-pbpk-platform/models/clearance_sota_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ best_model_fold_1.pt
‚îú‚îÄ‚îÄ best_model_fold_2.pt
‚îú‚îÄ‚îÄ best_model_fold_3.pt
‚îú‚îÄ‚îÄ best_model_fold_4.pt
‚îú‚îÄ‚îÄ best_model_fold_5.pt
‚îú‚îÄ‚îÄ training.log
‚îî‚îÄ‚îÄ results.json

/workspace/darwin-pbpk-platform/logs/
‚îî‚îÄ‚îÄ clearance_sota_training_YYYYMMDD_HHMMSS.log
```

### 4. Parar Job (se necess√°rio)

```bash
kubectl delete job clearance-sota-training -n darwin-pbpk-platform
```

---

## ‚öôÔ∏è Configura√ß√£o do Job

O job executa o seguinte comando:

```bash
python3 apps/training/03_single_task_clearance_multimodal.py \
    --output-dir "$OUTPUT_DIR" \
    --device cuda \
    --batch-size 32 \
    --epochs 100 \
    --lr 1e-4 \
    --patience 15 \
    --num-folds 5
```

**Par√¢metros configur√°veis:**
- `--output-dir`: Diret√≥rio de sa√≠da (com timestamp autom√°tico)
- `--device`: cuda/cpu
- `--batch-size`: Tamanho do batch (padr√£o: 32)
- `--epochs`: N√∫mero de √©pocas (padr√£o: 100)
- `--lr`: Learning rate (padr√£o: 1e-4)
- `--patience`: Early stopping patience (padr√£o: 15)
- `--num-folds`: N√∫mero de folds para CV (padr√£o: 5)

---

## üìä Depend√™ncias Instaladas no Job

O job instala automaticamente:

- **PyTorch:** Pr√©-instalado na imagem
- **PyTorch Geometric:** `torch-geometric` + extensions CUDA
- **Transformers:** Para ChemBERTa
- **RDKit:** Para descritores moleculares
- **PyTDC:** Para carregar datasets TDC diretamente
- **Scikit-learn:** Para m√©tricas e cross-validation
- **Outras:** numpy, scipy, pandas, matplotlib, tqdm, pydantic

---

## üîç Troubleshooting

### Job n√£o inicia
```bash
# Verificar eventos do namespace
kubectl get events -n darwin-pbpk-platform --sort-by='.lastTimestamp'

# Ver detalhes do pod
kubectl describe pod <pod-name> -n darwin-pbpk-platform
```

### GPU n√£o dispon√≠vel
```bash
# Verificar se node Maria tem GPU
kubectl describe node maria | grep -i gpu

# Verificar se device plugin est√° configurado
kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, gpu: .status.capacity."nvidia.com/gpu"}'
```

### Erro de mem√≥ria
- Reduzir `--batch-size` no job YAML
- Aumentar `memory.limits` no job YAML

### Dataset n√£o encontrado
- O script tem fallback autom√°tico para TDC
- Verificar logs para mensagens de fallback

---

## üìù Pr√≥ximos Passos

1. ‚úÖ Job Kubernetes criado
2. ‚úÖ Scripts de submiss√£o e monitoramento criados
3. ‚úÖ Script de treinamento atualizado com argparse
4. ‚è≥ **Submeter job e monitorar execu√ß√£o**
5. ‚è≥ Validar resultados (R¬≤ > 0.50)
6. ‚è≥ Comparar com benchmarks da literatura
7. ‚è≥ Publicar resultados cient√≠ficos

---

## üéì Metodologia Cient√≠fica

- **Single-task learning:** Foco em Clearance (evita missing data de multi-task)
- **Multimodal encoder:** 976d (ChemBERTa 768d + GNN 128d + KEC 32d + 3D 16d + QM 32d)
- **Cross-validation:** 5-fold independente (rigor cient√≠fico)
- **Early stopping:** Patience 15 √©pocas (evita overfitting)
- **M√©tricas:** R¬≤, RMSE, MAE (padr√£o da literatura)

---

**√öltima atualiza√ß√£o:** 2025-11-08

