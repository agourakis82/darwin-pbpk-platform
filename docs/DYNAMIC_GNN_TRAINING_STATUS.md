# ğŸš€ Dynamic GNN PBPK - Status do Treinamento

**Data:** 06 de Novembro de 2025  
**Status:** âœ… **TREINAMENTO FUNCIONANDO**

---

## âœ… PROBLEMA RESOLVIDO

### Bug Identificado:
- **Problema:** Modelo retornava apenas 2 pontos temporais em vez de 100
- **Causa:** DataLoader criava batch de `time_points` com shape `[batch_size, 100]` em vez de `[100]`
- **Sintoma:** `pred_conc: torch.Size([14, 2])` quando deveria ser `[14, 100]`

### SoluÃ§Ã£o:
```python
# DataLoader pode criar batch de time_points incorretamente se for 1D
# Garantir que time_points Ã© 1D (mesmo para todas as amostras)
if time_points.dim() > 1:
    time_points = time_points[0]  # Pegar primeira amostra (todas sÃ£o iguais)
```

**Aplicado em:**
- `train_epoch()` - Treinamento
- `validate()` - ValidaÃ§Ã£o

---

## ğŸ“Š RESULTADOS DO TREINAMENTO

### Teste RÃ¡pido (100 amostras, 2 Ã©pocas):
- **Ã‰poca 1:** Train Loss: 13.05, Val Loss: 50.25
- **Ã‰poca 2:** Train Loss: 10.90, Val Loss: 36.43 âœ…
- **Melhoria:** Val Loss reduziu 27% em 2 Ã©pocas

### Shapes Corretos:
- âœ… `pred_conc: [14, 100]` (correto!)
- âœ… `true_conc: [14, 100]` (correto!)
- âœ… `time_points: [100]` (correto!)

---

## ğŸ¯ PRÃ“XIMOS PASSOS

### 1. Treinamento Completo (Recomendado)
```bash
# Dataset completo (1000 amostras)
python3 scripts/train_dynamic_gnn_pbpk.py \
    --data data/dynamic_gnn_training_full/training_data.npz \
    --output models/dynamic_gnn_full \
    --epochs 50 \
    --batch-size 8 \
    --lr 1e-3 \
    --device cuda  # GPU recomendado!
```

**Tempo estimado:**
- CPU: ~6-8 horas (muito lento, ~2s/it)
- GPU: ~30-60 minutos (recomendado)

### 2. ValidaÃ§Ã£o vs ODE Solver
- Comparar prediÃ§Ãµes do modelo treinado vs ODE solver
- Calcular RÂ², RMSE, MAE
- Target: RÂ² > 0.90 (SOTA do paper)

### 3. OtimizaÃ§Ã£o
- Hyperparameter tuning (learning rate, architecture)
- Early stopping baseado em val loss
- Learning rate scheduling

---

## ğŸ“ ARQUIVOS

### Modelos Treinados:
- `models/dynamic_gnn_fixed/best_model.pt` - Melhor validaÃ§Ã£o (teste rÃ¡pido)
- `models/dynamic_gnn_fixed/final_model.pt` - Ãšltima Ã©poca
- `models/dynamic_gnn_fixed/training_curve.png` - Curva de treinamento

### Datasets:
- `data/dynamic_gnn_training/training_data.npz` - 100 amostras (teste)
- `data/dynamic_gnn_training_full/training_data.npz` - 1000 amostras (completo)

---

## ğŸ”§ CONFIGURAÃ‡ÃƒO RECOMENDADA

### Para Treinamento RÃ¡pido (Teste):
- Dataset: 100-500 amostras
- Ã‰pocas: 5-10
- Batch size: 4-8
- Device: CPU (OK para teste)

### Para Treinamento Completo:
- Dataset: 1000-5000 amostras
- Ã‰pocas: 50-100
- Batch size: 8-16
- Device: **GPU (ESSENCIAL!)**
- Learning rate: 1e-3 a 1e-4

---

## ğŸ“ˆ MÃ‰TRICAS ESPERADAS

### Baseado no Paper (arXiv 2024):
- **RÂ²:** 0.9342 (target)
- **RMSE:** 0.0159
- **MAE:** 0.0116

### Status Atual:
- âœ… Treinamento funcionando
- âœ… Shapes corretos
- â³ ValidaÃ§Ã£o vs ODE pendente
- â³ MÃ©tricas finais pendentes

---

## ğŸ› BUGS CORRIGIDOS

1. âœ… **Shape mismatch** - pred_conc vs true_conc
2. âœ… **Time points batch** - DataLoader criando shape incorreto
3. âœ… **Per-organ losses** - Simplificado para evitar erros

---

## ğŸ’¡ NOTAS

- **Performance:** Treinamento em CPU Ã© muito lento (~2s/it). GPU essencial para treinamento completo.
- **ConvergÃªncia:** Modelo estÃ¡ aprendendo (loss diminuindo), mas precisa mais Ã©pocas.
- **ValidaÃ§Ã£o:** Val loss ainda alto (36.43), mas melhorando. Precisa mais treinamento.

---

**"Rigorous science. Honest results. Real impact."**

**Ãšltima atualizaÃ§Ã£o:** 2025-11-06

