#!/bin/bash
# Script para executar no node maria via RDMA/filesystem compartilhado
# Este script pode ser executado diretamente no node maria

echo "================================================================================"
echo "TREINAMENTO DYNAMIC GNN - Node Maria (L4 24GB)"
echo "================================================================================"
echo ""

# Verificar se estamos no node maria
HOSTNAME=$(hostname)
echo "üìç Hostname: $HOSTNAME"

# Verificar GPU
echo ""
echo "üîç Verificando GPU..."
if command -v nvidia-smi &> /dev/null; then
    GPU_INFO=$(nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader)
    echo "$GPU_INFO"
    GPU_COUNT=$(nvidia-smi --list-gpus | wc -l)
    echo "   GPUs detectadas: $GPU_COUNT"
    
    # Verificar se √© L4
    if echo "$GPU_INFO" | grep -qi "L4"; then
        echo "‚úÖ L4 24GB detectada!"
        BATCH_SIZE=32  # Otimizado para L4
    else
        echo "‚ö†Ô∏è  GPU diferente detectada, usando batch_size padr√£o"
        BATCH_SIZE=16
    fi
else
    echo "‚ùå nvidia-smi n√£o encontrado!"
    exit 1
fi

echo ""

# Verificar dataset
echo "üì¶ Verificando dataset..."
DATA_PATH="data/dynamic_gnn_training_full/training_data.npz"

if [ ! -f "$DATA_PATH" ]; then
    echo "‚ùå Dataset n√£o encontrado: $DATA_PATH"
    echo ""
    echo "Op√ß√µes:"
    echo "1. Copiar do node atual (se workspace n√£o for compartilhado):"
    echo "   scp DemetriosPCS:~/workspace/darwin-pbpk-platform/$DATA_PATH $DATA_PATH"
    echo ""
    echo "2. Gerar novo dataset:"
    echo "   python3 scripts/generate_dynamic_gnn_training_data.py \\"
    echo "       --num-samples 1000 \\"
    echo "       --output-dir data/dynamic_gnn_training_full"
    exit 1
fi

DATA_SIZE=$(du -h "$DATA_PATH" | cut -f1)
echo "‚úÖ Dataset encontrado: $DATA_PATH ($DATA_SIZE)"
echo ""

# Verificar se treinamento j√° est√° rodando
if pgrep -f "train_dynamic_gnn_pbpk.py" > /dev/null; then
    echo "‚ö†Ô∏è  Treinamento j√° est√° rodando!"
    PID=$(pgrep -f "train_dynamic_gnn_pbpk.py" | head -1)
    echo "   PID: $PID"
    echo ""
    echo "üìä Para monitorar:"
    echo "   tail -f training_maria.log"
    echo ""
    echo "üõë Para parar:"
    echo "   kill $PID"
    exit 0
fi

# Configura√ß√µes
OUTPUT_DIR="models/dynamic_gnn_maria"
EPOCHS=50
LR=1e-3

echo "‚öôÔ∏è  Configura√ß√£o:"
echo "   Dataset: $DATA_PATH"
echo "   Output: $OUTPUT_DIR"
echo "   √âpocas: $EPOCHS"
echo "   Batch size: $BATCH_SIZE (otimizado para GPU dispon√≠vel)"
echo "   Learning rate: $LR"
echo ""

# Criar diret√≥rio de output
mkdir -p "$OUTPUT_DIR"

# Iniciar treinamento
echo "üöÄ Iniciando treinamento..."
echo "   Log: training_maria.log"
echo "   Modelos: $OUTPUT_DIR"
echo ""

nohup python3 scripts/train_dynamic_gnn_pbpk.py \
    --data "$DATA_PATH" \
    --output "$OUTPUT_DIR" \
    --epochs "$EPOCHS" \
    --batch-size "$BATCH_SIZE" \
    --lr "$LR" \
    --device cuda \
    > training_maria.log 2>&1 &

TRAIN_PID=$!
echo "‚úÖ Treinamento iniciado! PID: $TRAIN_PID"
echo ""
echo "üìä Monitorar progresso:"
echo "   tail -f training_maria.log"
echo ""
echo "üõë Parar treinamento:"
echo "   kill $TRAIN_PID"
echo ""

# Aguardar e mostrar in√≠cio
sleep 5
echo "üìã Primeiras linhas do log:"
echo "--------------------------------------------------------------------------------"
tail -20 training_maria.log 2>/dev/null || echo "Log ainda n√£o dispon√≠vel, aguarde alguns segundos..."

echo ""
echo "================================================================================"
echo "‚úÖ TREINAMENTO INICIADO!"
echo "================================================================================"

